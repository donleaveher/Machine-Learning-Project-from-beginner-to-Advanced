{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4da3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.p1 = nn.Conv2d(in_channels = in_channels, out_channels=c1, kernel_size=1)\n",
    "        self.p2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=c2[0], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=c2[0],out_channels=c2[1],kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.p3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=c3[0],kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=c3[0],out_channels=c3[1],kernel_size=5, padding=2)\n",
    "        )\n",
    "        self.p4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=c4, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        o1 = F.relu(self.p1(x))\n",
    "        o2 = F.relu(self.p2(x))\n",
    "        o3 = F.relu(self.p3(x))\n",
    "        o4 = F.relu(self.p4(x))\n",
    "\n",
    "        return torch.concat((o1,o2,o3,o4), dim=1)\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2,padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.inception1 = InceptionBlock(192,64,[96,128],[16,32],32)\n",
    "\n",
    "        self.b3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception2 = InceptionBlock(256, 128, [128, 192], [32, 96], 64)\n",
    "        self.inception3 = InceptionBlock(480, 192, [96,208],[16,48],64)\n",
    "        self.inception4 = InceptionBlock(512, 160,[112,224],[24,64],64)\n",
    "        self.inception5 = InceptionBlock(512, 128, [128, 256],[24,64],64)\n",
    "        self.inception6 = InceptionBlock(512, 112, [128,288],[32,64],64)\n",
    "        self.inception7 = InceptionBlock(528, 256, [160,320],[32,128],128)\n",
    "        self.inception8 = InceptionBlock(832, 256, [160,320],[32,128],128)\n",
    "        self.inception9 = InceptionBlock(832, 384,[192,384],[48,128],128)\n",
    "\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if(isinstance(m, nn.Conv2d)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.inception7(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.inception9(x)\n",
    "\n",
    "        x = self.b4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model = GoogLeNet().to(device)\n",
    "    summary(model, (1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d1195",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GoogLeNet.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2575389248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mgoogLeNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_data_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: GoogLeNet.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torchinfo import summary\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "def train_val_data_process():\n",
    "    train_data = FashionMNIST(root='./GoogLeNet/data',\n",
    "                            train = True,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Resize(size=224), \n",
    "                            transforms.Grayscale(num_output_channels=3),\n",
    "                            transforms.ToTensor()]),\n",
    "                            download=True)\n",
    "    \n",
    "    train_data, val_data = Data.random_split(train_data, [round(0.8*len(train_data)), round(0.2*len(train_data))])\n",
    "\n",
    "    train_dataloader = Data.DataLoader(dataset=train_data,\n",
    "                                       batch_size = 64,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=0)\n",
    "    val_dataloader = Data.DataLoader(dataset=val_data,\n",
    "                                       batch_size = 64,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=0)\n",
    "    \n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def train_model_process(model, train_dataloader, val_dataloader, epochs):\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_loss_all = []\n",
    "    val_loss_all = []\n",
    "    train_acc_all = []\n",
    "    val_acc_all = []\n",
    "\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        print(f'The {epoch}/{epochs} Epoch')\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        train_num = 0\n",
    "        val_num = 0\n",
    "\n",
    "        train_bar = tqdm(train_dataloader, desc=\"Train\")\n",
    "        for step, (b_x, b_y) in enumerate (train_bar):\n",
    "            b_x = b_x.to(device)\n",
    "            b_y = b_y.to(device)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            output = model(b_x)\n",
    "\n",
    "            pre_lab = torch.argmax(output, dim = 1)\n",
    "\n",
    "            data_loss = loss(output, b_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            data_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss+=data_loss.item()*b_x.size(0)\n",
    "            train_acc += torch.sum(pre_lab == b_y.data)\n",
    "\n",
    "            train_num += b_x.size(0)\n",
    "\n",
    "        test_bar = tqdm(val_dataloader, desc=\"Val\")\n",
    "        for step, (b_x, b_y) in enumerate (test_bar):\n",
    "            b_x = b_x.to(device)\n",
    "            b_y = b_y.to(device)\n",
    "\n",
    "            model.eval()\n",
    "            output = model(b_x)\n",
    "\n",
    "            pre_lab = torch.argmax(output, dim = 1)\n",
    "\n",
    "            data_loss = loss(output, b_y)\n",
    "\n",
    "            val_loss += data_loss.item()*b_x.size(0)\n",
    "            val_acc += torch.sum(pre_lab == b_y.data)\n",
    "            val_num += b_x.size(0)\n",
    "        \n",
    "        train_loss_all.append(train_loss/train_num)\n",
    "        train_acc_all.append(train_acc.item()/train_num)\n",
    "\n",
    "        val_loss_all.append(val_loss/val_num)\n",
    "        val_acc_all.append(val_acc.item()/val_num)\n",
    "        print(f\"{epoch} Train Loss: {train_loss_all[-1]:.4f} Train Acc: {train_acc_all[-1]:.4f}\")\n",
    "        print(f\"{epoch} Val Loss: {val_loss_all[-1]:.4f} Val Acc: {val_acc_all[-1]:.4f}\")\n",
    "\n",
    "        if val_acc_all[-1]>best_acc:\n",
    "            best_acc = val_acc_all[-1]\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        time_use = time.time()-epoch_start_time\n",
    "        print(f\"Time cost in Epoch {epoch} : {time_use}s\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    torch.save(best_model_wts, 'GoogLeNet/best_model.pth')\n",
    "\n",
    "    train_process = pd.DataFrame(data={\"epoch\":range(epochs),\n",
    "                                        \"train_loss_all\":train_loss_all,\n",
    "                                        \"val_loss_all\":val_loss_all,\n",
    "                                        \"train_acc_all\":train_acc_all,\n",
    "                                        \"val_acc_all\":val_acc_all})\n",
    "    return train_process\n",
    "\n",
    "\n",
    "\n",
    "def matplot_acc_loss(train_process):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_process[\"epoch\"], train_process.train_loss_all, 'ro-', label = \"train loss\")\n",
    "    plt.plot(train_process[\"epoch\"], train_process.val_loss_all, 'bs-', label = \"val loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_process[\"epoch\"], train_process.train_acc_all, 'ro-', label = \"train acc\")\n",
    "    plt.plot(train_process[\"epoch\"], train_process.val_acc_all, 'bs-', label = \"val acc\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__  == \"__main__\":\n",
    "    googLeNet = GoogLeNet()\n",
    "    train_dataloader, val_dataloader = train_val_data_process()\n",
    "\n",
    "    train_process = train_model_process(googLeNet, train_dataloader, val_dataloader, 20)\n",
    "\n",
    "    matplot_acc_loss(train_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f4edf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GoogLeNet.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3634218312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GoogLeNet/best_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: GoogLeNet.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "from torchinfo import summary\n",
    "import copy\n",
    "\n",
    "\n",
    "def test_val_data_process():\n",
    "    test_data = FashionMNIST(root='./GoogLeNet/data',\n",
    "                            train = False,\n",
    "                            transform=transforms.Compose([\n",
    "                            transforms.Resize(size=224), \n",
    "                            transforms.Grayscale(num_output_channels=3),\n",
    "                            transforms.ToTensor()]),\n",
    "                            )\n",
    "    \n",
    "\n",
    "    test_dataloader = Data.DataLoader(dataset=test_data,\n",
    "                                       batch_size = 32,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers = 0)\n",
    "    \n",
    "    return test_dataloader\n",
    "\n",
    "def test_model_process(model, test_dataloader):\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    test_acc = 0.0\n",
    "    test_num = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (b_x, b_y) in enumerate(test_dataloader):\n",
    "            b_x = b_x.to(device)\n",
    "            b_y = b_y.to(device)\n",
    "\n",
    "            model.eval()\n",
    "            output = model(b_x)\n",
    "            pre_lab = torch.argmax(output, dim=1)\n",
    "\n",
    "            test_acc += torch.sum(pre_lab==b_y.data)\n",
    "            test_num += b_x.size(0)\n",
    "        \n",
    "    \n",
    "    print(f\"The accuracy of testing: {test_acc/test_num}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = GoogLeNet()\n",
    "\n",
    "    model.load_state_dict(torch.load('GoogLeNet/best_model.pth'))\n",
    "    test_loader = test_val_data_process()\n",
    "\n",
    "    test_model_process(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
